# ğŸ§ª TruthChecker â€“ Hallucination Detection for LLMs

**Version 1.0 â€“ Maintained by Elloe AI**  
ğŸ“„ [Read the Whitepaper](https://whitepapers.elloe.ai/whitepaper/)  
ğŸŒ [Docs Portal](https://whitepapers.elloe.ai) | ğŸ§¬ [Elloe AI](https://elloe.ai)

---

## âš¡ Overview

**TruthChecker** is a compliance-grade hallucination detection engine designed for auditing the outputs of large language models (LLMs) in high-stakes environments.

Built by the creators of the [Immune System for AI](https://github.com/Elloe-AI/immune-system-ai), TruthChecker is used across:

- Healthcare (HIPAA)
- Financial services (GDPR, SOC2)
- Legal tech (EU AI Act)
- AI research & open source risk audits

---

## ğŸ” Key Features

âœ… SHAP explainability & token-level attributions  
âœ… Pattern-based claim verification (e.g. absolutes, speculative language)  
âœ… Ground truth comparison via PubMed/ICD10/SEC JSON loaders  
âœ… Append-only audit logging (`.jsonl`)  
âœ… CLI, API, and YAML contract support  
âœ… Integrates with Obsidian, dashboards, or your CI pipeline

---

## ğŸš€ Quick Start

```bash
pip install truthchecker
```

```python
from truthchecker.validator import TruthChecker

checker = TruthChecker()
result = checker.validate("LLMs always tell the truth.")
print(result)
```

**Output:**
```json
{
  "verdict": "false",
  "confidence": 0.50,
  "reason": "Contains absolute claim ('always')"
}
```

Or use via CLI:
```bash
truthchecker "AI models never hallucinate."
```

---

## ğŸ“˜ Docs & Research

- ğŸ“„ [Whitepaper (PDF)](https://whitepapers.elloe.ai/whitepaper.pdf)
- ğŸ“˜ [Full Documentation](https://whitepapers.elloe.ai)
- ğŸ“š [Compliance Use Cases](https://whitepapers.elloe.ai/compliance)

---

## ğŸ§ª Testing

```bash
pytest tests/
```

---

## ğŸ“ Project Structure

```
truthchecker/
â”œâ”€â”€ validator.py         # Core logic
â”œâ”€â”€ cli.py               # CLI tool
â”œâ”€â”€ contracts/           # YAML validation contracts
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ check_example.py
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_validator.py
â”œâ”€â”€ docs/
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE (Apache 2.0)
```

---

## ğŸ“¤ Contributing

We welcome PRs for:

- ğŸ§  New rule patterns (e.g. speculative language)
- ğŸ“š Domain loaders (clinical, legal, financial)
- ğŸ§ª SHAP visualizers or integrations

---

## ğŸ”’ License

Apache 2.0 â€“ Open source, secure by default.  
By Elloe AI | Contact: [jambo@elloe.ai](mailto:jambo@elloe.ai)

> "Verification is the immune system for LLMs. TruthChecker is your first line of defense."

---

## âœ¨ Related Projects

- ğŸ§¬ [Immune System for AI](https://github.com/Elloe-AI/immune-system-ai) â€“ Enterprise compliance engine for regulated LLMs
- ğŸ” [AutoRAG](https://github.com/Elloe-AI/autorag) â€“ Retrieval-augmented reasoning with citation enforcement
- ğŸ” [SentinelAI](https://github.com/Elloe-AI/sentinelai) â€“ Real-time SHAP-based LLM risk monitor

---

## ğŸš€ Badges

![License](https://img.shields.io/github/license/Elloe-AI/truthchecker)
![Build](https://github.com/Elloe-AI/truthchecker/actions/workflows/tests.yml/badge.svg)
[![Docs](https://img.shields.io/badge/docs-available-blue)](https://whitepapers.elloe.ai/truthchecker)
[![PyPI](https://img.shields.io/pypi/v/truthchecker)](https://pypi.org/project/truthchecker/) 